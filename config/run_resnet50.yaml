model_name: resnet # model name
backbone_name: resnet50  # backbone name
num_classes: 2
log_dir: ./log
seed: 42
pretrained: true
backbone_freeze_epoch: 1
train_dataset_configs: [
#  config/dataset/in-train-batch128.yaml,
  config/dataset/cross-train-batch128.yaml,
]

val_dataset_configs: null

test_dataset_configs: [
  config/dataset/test_SageMaker.yaml,
  config/dataset/test_DiT.yaml,
]

test_after_every_epoch: true

# mean and std for normalization
mean: [0.485, 0.456, 0.406]
std: [0.229, 0.224, 0.225]

# optimizer config
optimizer:
  # choose between 'adam' and 'sgd'
  base: adam
  additional: null
  adam:
    lr: 0.0005  # learning rate
    betas: [0.9, 0.999]  # betas for Adam optimizer
    eps: 0.00000001  # epsilon for Adam optimizer
    weight_decay: 0.0001  # weight decay for regularization
    amsgrad: false
  sam:
    rho: 0.05
    warm_up: 1
    affect_classifier: false
    affect_fake_only: true
    start_epoch: 2
  is-sam:
    rho: 0.05
    start_epoch: 2

# training config
resolution: 224   # resolution of output image to network
lr_scheduler: step   # learning rate scheduler
lr_step: 5
lr_gamma: 0.1
n_epochs: 10   # number of epochs to train for
start_epoch: 0   # manual epoch number

# loss function
loss_func: cross_entropy   # loss function to use
losstype: null

# metric
metric_scoring: auc   # metric for evaluation (auc, acc, eer, ap)
cuda: true   # whether to use CUDA acceleration
cudnn: true   # whether to use CuDNN for convolution operations

# data augmentation
use_data_augmentation: true  # Add this flag to enable/disable data augmentation
data_aug:
  flip_prob: 0.5
  brightness_limit: 0.1
  contrast_limit: 0.1
  saturation_limit: 0.1
  hue_limit: 0.05